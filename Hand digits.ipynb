{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(some_array):\n",
    "    oh = np.zeros((len(some_array), np.max(some_array) + 1))\n",
    "    oh[np.arange(len(some_array)), some_array] = 1\n",
    "    return oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (1000, 8, 8)\n",
      "Dev set shape: (797, 8, 8)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "\n",
    "images = digits.images\n",
    "labels = digits.target\n",
    "\n",
    "images, labels = shuffle(images, labels, random_state=0)\n",
    "\n",
    "train_set = images[:1000]\n",
    "train_lab = one_hot(labels[:1000])\n",
    "dev_set = images[1000:]\n",
    "dev_lab = one_hot(labels[1000:])\n",
    "\n",
    "print(\"Training set shape: {}\".format(train_set.shape))\n",
    "print(\"Dev set shape: {}\\n\".format(dev_set.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set after reshaping: (64, 1000)\n",
      "Dev set after reshaping: (64, 797)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_set = train_set.reshape(train_set.shape[0], -1).T/255\n",
    "dev_set = dev_set.reshape(dev_set.shape[0], -1).T/255\n",
    "\n",
    "print(\"Training set after reshaping: {}\".format(train_set.shape))\n",
    "print(\"Dev set after reshaping: {}\\n\".format(dev_set.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(Z):\n",
    "    numer = np.exp(Z)\n",
    "    denom = np.sum(numer)\n",
    "    \n",
    "    s = numer / denom\n",
    "    return s, Z\n",
    "\n",
    "def relu(Z):\n",
    "    r = np.maximum(0, Z)\n",
    "    return r, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = train_set.shape[1]\n",
    "n_x = train_set.shape[0]\n",
    "n_y = 10\n",
    "layers_dim = [n_x, 5, n_y]\n",
    "L = len(layers_dim)\n",
    "\n",
    "parameters = {}\n",
    "\n",
    "for i in range(1, L):\n",
    "    parameters['W' + str(i)] = np.random.randn(layers_dim[i-1], layers_dim[i]) * 0.01\n",
    "    parameters['b' + str(i)] = np.zeros((layers_dim[i], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_lin(A, W, b):\n",
    "    \n",
    "    Z = np.dot(W.T, A) + b\n",
    "    cache = (A, W, b)\n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_act(A_prev, W, b, activation):\n",
    "    if activation == 'relu':\n",
    "        Z, cache_lin = forward_lin(A_prev, W, b)\n",
    "        A, cache_act = relu(Z)\n",
    "    elif activation == 'softmax':\n",
    "        Z, cache_lin = forward_lin(A_prev, W, b)\n",
    "        A, cache_act = softmax(Z)\n",
    "\n",
    "    cache = (cache_lin, cache_act)\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(output, labels):\n",
    "    cost = -np.sum(labels*np.log(output) + (1 - labels)*np.log(1 - output))/len(labels)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_lin(dZ, cache):\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "    \n",
    "    dW = (np.dot(A_prev, dZ.T))/m\n",
    "    db = np.sum(dZ)/m\n",
    "    dA_prev = np.dot(W.T, dZ)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_back(dA_prev, dW, db, activation):\n",
    "    \n",
    "    if activation == 'relu':\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_prev = train_set\n",
    "Y = train_lab\n",
    "L = len(parameters)//2\n",
    "caches = []\n",
    "\n",
    "for i in range(1, L):\n",
    "    A_prev, cache = forward_act(A_prev, parameters['W' + str(i)], parameters['b' + str(i)], 'relu')\n",
    "    caches.append(cache)\n",
    "\n",
    "A_prev, cache = forward_act(A_prev, parameters['W' + str(L)], parameters['b' + str(L)], 'softmax')\n",
    "caches.append(cache)\n",
    "\n",
    "dZ = A_prev - Y.T\n",
    "dW ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9.99998375e-05   1.00000512e-04   1.00001872e-04   9.99989835e-05\n",
      "   1.00001888e-04   1.00000188e-04   9.99995699e-05   9.99995064e-05\n",
      "   1.00000026e-04   9.99977472e-05]\n",
      "[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[  9.99998375e-05   1.00000512e-04  -9.99899998e-01   9.99989835e-05\n",
      "   1.00001888e-04   1.00000188e-04   9.99995699e-05   9.99995064e-05\n",
      "   1.00000026e-04   9.99977472e-05]\n"
     ]
    }
   ],
   "source": [
    "print(AL[:, 0])\n",
    "print(Y.T[:, 0])\n",
    "print(dZ[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
